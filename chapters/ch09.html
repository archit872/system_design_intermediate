<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Chapter 09 — Capstone Project — Full System Design & Implementation</title>
  <meta name="description" content="Plan and deliver a production‑grade prototype: choose a domain, define NFRs and SLOs, design the architecture, implement with CI/CD, instrument observability, run load/chaos tests, and write a postmortem. Includes rubric and week‑by‑week milestones.">
  <meta property="og:title" content="Chapter 09 — Capstone Project — Full System Design & Implementation">
  <meta property="og:description" content="A guided path from requirements to a working system: deliverables, milestones, evaluation rubric, and detailed examples for analytics, checkout, and chat presence.">
  <meta property="og:type" content="article">
  <base href="../">
  <link rel="stylesheet" href="styles/theme.css">
  <script src="scripts/app.js" defer></script>
</head>
<body>
  <a class="skip-link" href="#main">Skip to main content</a>

  <header class="app-nav">
    <div class="container inner">
      <div class="brand">Intermediate System Design</div>
      <button class="toggle js-nav-toggle" aria-expanded="false" aria-controls="top-menu">☰ Menu</button>
      <nav id="top-menu" class="menu" aria-label="Primary">
        <a href="index.html">Home</a>
        <a href="chapters/appendix.html">Appendix</a>
        <a href="chapters/glossary.html">Glossary</a>
      </nav>
    </div>
  </header>

  <main id="main" class="container fade-in">
    <section class="page-hero" id="9-hero">
      <div class="meta"><span class="badge badge-primary">Chapter 09</span></div>
      <h1>Capstone Project — Full System Design &amp; Implementation</h1>
      <p class="abstract">This is where your learning becomes a running system. You will select a realistic domain, write non‑functional requirements (NFRs) and SLOs, design an architecture, implement and deploy it with CI/CD, add observability, and validate reliability with load and chaos tests. You will finish with a blameless postmortem and a short architecture review. The capstone is sized for 8–12 weeks and demonstrates you can <em>design, justify, and operate</em> a production‑like service.</p>
    </section>

    <section class="section" id="9-1-overview">
      <h2>9.1 Overview: goals, deliverables, and domains</h2>
      <p><strong>Why it matters.</strong> Reading about systems is different from <em>running</em> one. The capstone turns abstract trade‑offs into concrete engineering decisions under constraints.</p>

      <h3 id="9-1-1-deliverables">9.1.1 Deliverables (what you will ship)</h3>
      <ul>
        <li><strong>Architecture document</strong> (6–10 pages): context, NFRs, SLOs, diagrams, data model, API contracts, risks, and ADRs (architectural decisions) with alternatives considered.</li>
        <li><strong>Working prototype</strong>: deployed to managed cloud/Kubernetes or serverless; automated build, test, and deploy; seed data; one-click bootstrap script.</li>
        <li><strong>Observability baseline</strong>: dashboards for SLIs, at least two alert rules tied to SLOs, and traces across the critical path.</li>
        <li><strong>Fault injection &amp; load results</strong>: one chaos experiment and a load test with analysis and actions.</li>
        <li><strong>Postmortem</strong>: one blameless postmortem from a test‑induced incident or a real defect found during the project.</li>
      </ul>

      <h3 id="9-1-2-domains">9.1.2 Domain choices (pick one)</h3>
      <ul>
        <li><strong>Real‑time product analytics</strong>: ingest click/view events, stream‑process features, serve dashboards and cohort queries.</li>
        <li><strong>Simplified checkout</strong>: price quotes, stock reservation, payment mock, and order lifecycle.</li>
        <li><strong>Chat with presence</strong>: messaging with typing indicators, online/offline state, and delivery receipts.</li>
      </ul>
      <p><em>Plain.</em> Choose a domain that exercises <em>data</em>, <em>scale</em>, and <em>reliability</em> concerns. <em>Formal.</em> Select based on variability in latency requirements, write/read mix, and integration surfaces. <em>Pitfall.</em> A toy scope that avoids trade‑offs (single table, single process, no failures) will not surface the skills this course targets. <em>Example.</em> If you pick chat, intentionally include bursty fan‑out and presence expiry; if you pick checkout, include price
to‑stock invariants and idempotent payments.</p>
    </section>

    <section class="section" id="9-2-milestones">
      <h2>9.2 Timeline, milestones, and cadence</h2>
      <p><strong>Why it matters.</strong> Timeboxing forces prioritization. Done beats perfect; measured beats guessed.</p>

      <h3 id="9-2-1-schedule">9.2.1 Suggested 8–12 week schedule</h3>
      <ul>
        <li><strong>Milestone 0 (Week 0)</strong>: Requirements, NFRs, initial wireframes, and scope agreements.</li>
        <li><strong>Milestone 1 (Weeks 1–3)</strong>: Component design, data model, API contracts; ADRs written; initial spike code.</li>
        <li><strong>Milestone 2 (Weeks 3–6)</strong>: Core services implemented; basic CI/CD; happy‑path E2E; seed data.</li>
        <li><strong>Milestone 3 (Weeks 6–9)</strong>: Deployment hardened; dashboards and alerts; load test; chaos experiment.</li>
        <li><strong>Milestone 4 (Weeks 9–12)</strong>: Polish; postmortem; external design review and demo.</li>
      </ul>

      <h3 id="9-2-2-checkpoints">9.2.2 Weekly checkpoints</h3>
      <ul>
        <li>One‑page design/update + one implemented test + a short demo video/gif.</li>
        <li>Track <em>risk burndown</em>: list top 3 unknowns; close at least one per week.</li>
        <li>Run a 30‑minute <em>critique</em> with a peer after Milestone 2; schedule the final review after Milestone 4.</li>
      </ul>
    </section>

    <section class="section" id="9-3-requirements-nfrs">
      <h2>9.3 From requirements to NFRs (and SLOs)</h2>
      <p><strong>Why it matters.</strong> Most failures stem from implicit requirements. Writing clear NFRs early prevents scope creep and enables <em>testable</em> promises.</p>

      <h3 id="9-3-1-translate">9.3.1 Translate features → NFRs</h3>
      <p><strong>Plain.</strong> NFRs constrain how the system behaves under load, failure, and change. <strong>Formal.</strong> Each feature should map to explicit targets for latency, availability, durability, correctness, security, and cost. <strong>Pitfall.</strong> Unmeasured “fast” or “reliable” claims; targets without measurement locations.</p>

      <p>Compare: <strong>Feature → NFR examples</strong></p>
      <table class="table">
        <thead><tr><th>Feature</th><th>NFR (target)</th><th>Measure at</th><th>Notes</th></tr></thead>
        <tbody>
          <tr><td>Checkout submit</td><td>P95 ≤ 300 ms; 99.9% success</td><td>Client + gateway</td><td>Block on price/stock commit; idempotent key</td></tr>
          <tr><td>Event ingest</td><td>P95 ingest ≤ 500 ms; 99.9% durability</td><td>Broker acks + storage commits</td><td>Backpressure + retries</td></tr>
          <tr><td>Presence updates</td><td>P95 send→receive ≤ 150 ms</td><td>Client spans</td><td>Expiry ≤ 60 s; tolerate 0.1% loss</td></tr>
        </tbody>
      </table>

      <h3 id="9-3-2-slo-defs">9.3.2 Write SLI/SLO definitions</h3>
      <p><strong>Plain.</strong> SLIs are ratios; SLOs set thresholds. <strong>Formal.</strong> “The proportion of <code>POST /checkout</code> requests completing under 300 ms with 2xx in the last 30 days ≥ 99.9%.” <strong>Pitfall.</strong> Forgetting to state <em>where</em> you measure; client and server differ.</p>

      <pre data-lang="yaml"><code># Example SLO spec (excerpt)
service: checkout
window: 30d
slis:
  availability: success/total  # 2xx/All at gateway
  latency_p95_ms: 300          # client‑measured
slos:
  availability: 
    target: 99.9
    burn_alerts:
      - fast: 14x over 5m
      - slow: 2x over 1h
  latency: 
    target: 95% under 300ms
    alert: +20% delta for 10m
</code></pre>

      <p><em>Analogy.</em> Think of SLOs like a household budget. You decide how much “failure spend” is acceptable per month (error budget) and track burn rate so you can slow down purchases (deploys) before the account hits zero.</p>
    </section>

    <section class="section" id="9-4-architecture">
      <h2>9.4 Architecture design: components, data, and integration</h2>
      <p><strong>Why it matters.</strong> A coherent architecture lets teams work independently yet produce a consistent user experience.</p>

      <h3 id="9-4-1-components">9.4.1 Component blueprint</h3>
      <p><strong>Plain.</strong> Choose the minimum set of services that preserve invariants and allow parallel work. <strong>Formal.</strong> Identify bounded contexts, single‑writer data ownership, and integration surfaces (sync/async) from Chapter 4. <strong>Pitfall.</strong> Decomposing by database tables or layering frameworks instead of cohesive capabilities.</p>
      <ul>
        <li><strong>Services:</strong> name, purpose, owner, datastore, external dependencies, and SLIs.</li>
        <li><strong>Data flows:</strong> read models, caches, and materialized views with freshness SLIs and rebuild plans.</li>
        <li><strong>Integration:</strong> REST/gRPC for request/response; events for fan‑out and side‑effects; contract tests for both.</li>
      </ul>

      <h3 id="9-4-2-data">9.4.2 Data model &amp; storage</h3>
      <p><strong>Plain.</strong> Select stores by workload (Chapter 3). <strong>Formal.</strong> OLTP for correctness, columnar for analytics, TSDB for metrics, object storage for blobs; partitioning and indexing based on hot paths. <strong>Pitfall.</strong> One‑size‑fits‑all databases; ignoring hot‑key risk.</p>
      <ul>
        <li><strong>Schema:</strong> list primary keys and indexes for hot endpoints; justify denormalization and state staleness bounds.</li>
        <li><strong>Sharding:</strong> key choice with hot‑partition mitigation; plan rebalancing and backfills.</li>
        <li><strong>Retention:</strong> data lifecycle policies for metrics/logs/PII.</li>
      </ul>

      <h3 id="9-4-3-contracts">9.4.3 Contracts &amp; versioning</h3>
      <p><strong>Plain.</strong> Version‑tolerant APIs enable independent deploys. <strong>Formal.</strong> Publish schemas, adopt additive changes first, and run consumer‑driven contract tests. <strong>Pitfall.</strong> Shared DBs; renames without alias/deprecation windows.</p>

      <pre data-lang="json"><code>{
  "endpoint": "POST /quotes",
  "request": { "sku": "string", "qty": "number", "currency": "ISO4217" },
  "response": { "price_cents": "number", "expires_in_s": "number", "promo_code?": "string" },
  "errors": [400, 409, 429, 500],
  "compat": "Additive fields allowed; prev fields preserved 90 days"
}</code></pre>
    </section>

    <section class="section" id="9-5-implementation">
      <h2>9.5 Implementation &amp; CI/CD</h2>
      <p><strong>Why it matters.</strong> Execution converts diagrams into behavior. CI/CD ensures behavior evolves safely.</p>

      <h3 id="9-5-1-environments">9.5.1 Environments and pipeline</h3>
      <p><strong>Plain.</strong> Define a minimum path: <em>dev → staging → prod</em>. <strong>Formal.</strong> Git mainline with PR checks; build once &amp; promote; progressive delivery with canary steps and automated rollback on SLI deltas (Chapter 7). <strong>Pitfall.</strong> Building different artifacts per environment; manual deployments without audit trail.</p>

      <p>Compare: <strong>CI/CD pipeline checklist</strong></p>
      <table class="table">
        <thead><tr><th>Stage</th><th>Gates</th><th>Artifacts</th><th>Notes</th></tr></thead>
        <tbody>
          <tr><td>Build</td><td>Unit tests; linters; SCA</td><td>Container image / package</td><td>Immutable tags; SBOM captured</td></tr>
          <tr><td>Staging</td><td>Contract tests; E2E; seed data</td><td>Deployment manifest</td><td>Trace sampling higher in staging</td></tr>
          <tr><td>Prod canary</td><td>SLI deltas within thresholds</td><td>Release notes</td><td>Auto‑rollback & notify</td></tr>
          <tr><td>Prod full</td><td>Post‑deploy smoke; dashboards</td><td>Signed release</td><td>Flag debt logged with expiry</td></tr>
        </tbody>
      </table>

      <h3 id="9-5-2-quality">9.5.2 Quality bars</h3>
      <ul>
        <li>Unit tests for domain logic; contract tests for APIs/events; integration tests for critical paths.</li>
        <li>Load tests for the bottleneck service; chaos experiments with abort conditions and rollbacks.</li>
        <li>Runbooks for top 3 risks; reproducible local dev with scripts/makefiles.</li>
      </ul>
    </section>

    <section class="section" id="9-6-observability">
      <h2>9.6 Observability &amp; operations</h2>
      <p><strong>Why it matters.</strong> You cannot validate SLOs or debug incidents without signals tied to user experience.</p>

      <h3 id="9-6-1-slis">9.6.1 SLIs, dashboards, and alerts</h3>
      <ul>
        <li><strong>Metrics:</strong> request rate, error rate, latency (P95/P99), saturation. Add exemplars linking to traces.</li>
        <li><strong>Traces:</strong> instrument critical path; include tenant/user cohort attributes (bounded cardinality).</li>
        <li><strong>Logs:</strong> structured JSON; redact secrets; sample verbose paths.</li>
        <li><strong>Alerts:</strong> burn‑rate pairs for SLOs; page on symptoms, ticket for capacity or cleanup.</li>
      </ul>

      <h3 id="9-6-2-game-days">9.6.2 Game days and chaos</h3>
      <p><strong>Plain.</strong> Practice incidents deliberately. <strong>Formal.</strong> Define a steady‑state, inject a fault (latency, kill pod, expire cert), and measure SLI impact and operator response. <strong>Pitfall.</strong> No abort criteria; running chaos without on‑call aware.</p>

      <pre data-lang="md"><code>### Chaos template
Hypothesis: Checkout P95 stays &lt; 300ms with +150ms on Pricing.
Fault: Inject +150ms latency on /price in staging, then 5% prod behind a flag.
Abort: SLI delta &gt; 20% for 5 minutes or error rate +0.5%.
Owners: SRE + Feature team.
Actions: Circuit opens; fallback to cached quotes.</code></pre>
    </section>

    <section class="section" id="9-7-security">
      <h2>9.7 Security baseline</h2>
      <p><strong>Why it matters.</strong> Security is part of reliability and user trust.</p>
      <ul>
        <li>Secrets via a manager or workload identity; no secrets in code or repo history; rotate automatically.</li>
        <li>Mutual TLS between services; least‑privilege IAM; policy as code for infra changes.</li>
        <li>Threat model the critical path; validate inputs; parameterized queries; safe deserialization; CSP/HSTS for web.</li>
        <li>Data classification, retention policies, and right‑to‑erasure workflows where applicable.</li>
      </ul>
    </section>

    <section class="section" id="9-8-examples">
      <h2>9.8 Worked examples (choose one to emulate)</h2>
      <p><strong>Why it matters.</strong> Concrete reference builds help you scope your own project and avoid dead‑ends.</p>

      <h3 id="9-8-1-analytics">9.8.1 Real‑time analytics for product events</h3>
      <p><strong>Plain.</strong> Ingest browse/click/purchase events, compute features, and power dashboards and cohort queries. <strong>Formal.</strong> A log‑based pipeline with streaming and OLAP sinks; bounded‑staleness dashboards and backfill via object storage.</p>
      <ul>
        <li><strong>Ingest:</strong> HTTP collector → message broker with 32–48 partitions (adjust by throughput) and idempotency keys.</li>
        <li><strong>Process:</strong> stream job aggregates features (per product/user) with tumbling windows; write to TSDB for near‑real‑time graphs and to hourly Parquet in object storage.</li>
        <li><strong>Serve:</strong> a read API reads from TSDB for recent windows and from a columnar store for historical cohorts; cache hot dashboards.</li>
        <li><strong>SLOs:</strong> P95 ingest latency ≤ 500 ms; pipeline availability 99.9%; freshness P99 ≤ 120 s.</li>
        <li><strong>Tests:</strong> load test spikes to 2.5× steady; chaos drop 5% packets between processor and sink; verify retry/idempotency.</li>
      </ul>
      <p><em>Trade‑offs.</em> Two sinks increase complexity; benefit is fast dashboards and cheap analytics. Keep schemas shared and versioned to avoid drift.</p>

      <h3 id="9-8-2-checkout">9.8.2 Simplified e‑commerce checkout</h3>
      <p><strong>Plain.</strong> Quote price, reserve stock, take payment (mock), and place order with email confirmation. <strong>Formal.</strong> CP core for purchase invariants; AP side‑effects for emails/analytics.</p>
      <ul>
        <li><strong>Services:</strong> <em>Catalog</em> (read model), <em>Pricing</em> (quotes), <em>Inventory</em> (reservations), <em>Orders</em> (state machine), <em>Payments</em> (mock), <em>Notifier</em> (email).</li>
        <li><strong>Data:</strong> Orders store is the single writer of truth for order states; others expose read models with freshness bounds.</li>
        <li><strong>Flow:</strong> Client requests quote → creates order with idempotency key → reserve stock (pessimistic lock or queue) → mock charge → commit order → emit events for email/analytics.
        </li>
        <li><strong>Invariants:</strong> “price at purchase time” and “no oversell.”</li>
        <li><strong>SLOs:</strong> P95 checkout ≤ 300 ms; availability 99.9%. Compensation for charge failure refunds and releases stock (Saga).</li>
        <li><strong>Tests:</strong> canary with mobile cohort; chaos adds +150 ms on Pricing; load includes hot SKU spikes and cache misses.</li>
      </ul>
      <p><em>Trade‑offs.</em> Strong consistency on the narrow core increases latency; mitigate with fast storage and short critical sections; keep non‑critical paths async.</p>

      <h3 id="9-8-3-chat">9.8.3 Chat service with presence</h3>
      <p><strong>Plain.</strong> Direct messages with typing indicators and presence. <strong>Formal.</strong> AP for presence events, CP for authorization and message delivery guarantees.</p>
      <ul>
        <li><strong>Services:</strong> <em>Gateway</em>, <em>Presence</em> (LWW with expiry), <em>Messaging</em> (queues + store), <em>Profile</em> (authz), <em>Notifier</em> (push).</li>
        <li><strong>Data:</strong> Messages in an append‑only store with per‑conversation partitions; presence as LWW register per user; read replicas for fan‑out.</li>
        <li><strong>SLOs:</strong> P95 send→receive ≤ 150 ms; availability 99.9%; presence expiry ≤ 60 s.</li>
        <li><strong>Tests:</strong> load with 100× fan‑out bursts; chaos drops 1 pod/ minute in Presence; verify client fallbacks and backoff.</li>
      </ul>
      <p><em>Trade‑offs.</em> Eventual presence is acceptable; delivery must be correct. Use fencing tokens for single‑writer jobs and idempotency for client retries.</p>
    </section>

    <section class="section" id="9-9-evaluation">
      <h2>9.9 Evaluation rubric &amp; self‑assessment</h2>
      <p><strong>Why it matters.</strong> Clear grading criteria focus effort on the highest‑value work and make the final review predictable.</p>

      <p>Compare: <strong>Rubric (weights)</strong></p>
      <table class="table">
        <thead><tr><th>Dimension</th><th>Weight</th><th>What excellent looks like</th><th>Common misses</th></tr></thead>
        <tbody>
          <tr><td>Correctness</td><td>30%</td><td>Meets functional requirements with acceptance tests; edge cases handled</td><td>Happy path only; fragile assumptions</td></tr>
          <tr><td>Non‑functional</td><td>30%</td><td>Meets SLOs; passes load/chaos; clear capacity headroom</td><td>No SLOs; unmeasured regressions</td></tr>
          <tr><td>Observability &amp; ops</td><td>20%</td><td>Dashboards tied to SLIs; runbooks; alerts with burn‑rate</td><td>Metric soup; no runbooks</td></tr>
          <tr><td>Code &amp; docs</td><td>20%</td><td>Tests; ADRs; automated build/deploy; readable code</td><td>Manual steps; missing contracts</td></tr>
        </tbody>
      </table>

      <h3 id="9-9-1-self">9.9.1 Self‑review checklist (pre‑demo)</h3>
      <ul>
        <li>We can demo a user journey end‑to‑end with traces visible and logs redacted.</li>
        <li>We have SLO dashboards and two alerts bound to them; we know our current burn rate.</li>
        <li>We ran one chaos and one load test and captured actions; our postmortem has owner/dates.</li>
        <li>Our ADRs record at least two rejected alternatives with rationale.</li>
        <li>We can roll back code and configs in one command; schema changes follow expand/contract.</li>
      </ul>
    </section>

    <section class="section" id="9-10-exercises">
      <h2>9.10 Applied exercises</h2>
      <ol>
        <li><strong>Capstone pitch (1 page).</strong> State problem, users, three core features, and five NFRs with targets and measurement points. Include a sketch diagram and risks.</li>
        <li><strong>Contracts & data (2 pages).</strong> Define one API (OpenAPI/gRPC) and one event schema with versioning rules. Propose primary keys, indexes, and one materialized view with freshness SLI.</li>
        <li><strong>SLI & SLOs (1 page).</strong> Write two SLIs and an SLO with burn‑rate alerts. Attach a screenshot of a mock dashboard or a config snippet.</li>
        <li><strong>Load/chaos plan (1 page).</strong> Define arrival model, datasets (hot keys), and abort criteria. Include a rollback plan.</li>
        <li><strong>Postmortem (1 page).</strong> After your first induced failure, write a blameless postmortem with actions and owners. Schedule a follow‑up review.</li>
      </ol>
    </section>

    <section class="section" id="9-11-resources">
      <h2>9.11 Resources</h2>
      <ul>
        <li><strong>Kubernetes docs (deployment patterns)</strong> — manifests, probes, HPA, and service designs you can adapt. <em>Why:</em> production‑like deployment scaffolding. <em>(Free)</em></li>
        <li><strong>AWS Well‑Architected (reliability & cost lenses)</strong> — prompts for trade‑offs and reviews. <em>Why:</em> decision discipline before you pick a tool. <em>(Free)</em></li>
        <li><strong>Google SRE book/site</strong> — SLOs, alerting, incident workflows, and postmortems. <em>Why:</em> make reliability measurable. <em>(Free)</em></li>
        <li><strong>Microservices guidance (Fowler)</strong> — boundaries, contracts, and testing guidance. <em>Why:</em> avoid distributed monoliths. <em>(Free)</em></li>
        <li><strong>Designing Data‑Intensive Applications</strong> — deep dives on logs, storage, consistency, and projections. <em>Why:</em> principled data architecture. <em>(Paid)</em></li>
      </ul>
    </section>

    <section class="section" id="9-12-recap-next">
      <h2>Recap &amp; Next Steps</h2>
      <ul>
        <li>You have a template to turn requirements into NFRs and SLOs tied to user experience, not servers.</li>
        <li>You can design a minimal, cohesive architecture with owned data, clear contracts, and the right storage per workload.</li>
        <li>You can implement safely with CI/CD, validate with load and chaos, and explain reliability using dashboards and burn‑rate alerts.</li>
        <li>You can write ADRs and postmortems that document decisions and drive change.</li>
      </ul>
      <p><strong>Next:</strong> Proceed to <a href="chapters/ch10.html#10-hero">Chapter 10 — Pitfalls, Next Steps &amp; Optional Advanced Topics</a>, where we summarize common mistakes, map your next learning path, and preview advanced areas like multi‑region and platform engineering.</p>
    </section>

    <nav class="next-prev">
      <a class="btn" rel="prev" href="chapters/ch08.html">← Previous</a>
      <a class="btn btn-primary" rel="next" href="chapters/ch10.html">Next →</a>
    </nav>

    <footer class="site-footer">
      <div class="container">
        <p class="muted">© 2025 BookBuilder. Built with vanilla HTML/CSS/JS. Dark theme.</p>
      </div>
    </footer>
  </main>

  <!--
  CHECKLIST (Chapter 09)
  - [x] /styles/theme.css + /scripts/app.js linked; <base> correct; no inline nav JS
  - [x] Canonical nav (Home / Appendix / Glossary only)
  - [x] Pager prev → ch08, next → ch10; ToC numbering matches
  - [x] Order: Hero → Numbered Sections → Resources → Recap
  - [x] ≥1,800 words of prose (body text)
  - [x] Images: none (no audit required)
  - [x] Head/meta complete; no TODOs
  -->
</body>
</html>
